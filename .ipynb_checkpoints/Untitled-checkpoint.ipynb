{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.   0.   0.  18.   0.   0.   0.   0.   9.   0.   0.   0.   0.   3.   0.\n",
      "   0.   0.   0.   2.   0.   0.   0.   0.  15.   0.   0.   3.]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Training_Dataset.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    rows = []\n",
    "    features_train = []\n",
    "    labels_train = []\n",
    "    index = 0\n",
    "    for row in spamreader:\n",
    "        rows.append(row[0].split(','))\n",
    "        \n",
    "        #change 1st column to corresponding value in int\n",
    "        if rows[index][1] == \"Centaur\":\n",
    "            rows[index][1] = 0\n",
    "        elif rows[index][1] == \"Ebony\":\n",
    "            rows[index][1] = 1\n",
    "        elif rows[index][1] == \"Cosmos\":\n",
    "            rows[index][1] = 2\n",
    "        elif rows[index][1] == \"Tokugawa\":\n",
    "            rows[index][1] = 3\n",
    "        elif rows[index][1] == \"Odyssey\":\n",
    "            rows[index][1] = 4\n",
    "            \n",
    "        if rows[index][35] == \"Centaur\":\n",
    "            rows[index][35] = 0\n",
    "        elif rows[index][35] == \"Ebony\":\n",
    "            rows[index][35] = 1\n",
    "        elif rows[index][35] == \"Cosmos\":\n",
    "            rows[index][35] = 2\n",
    "        elif rows[index][35] == \"Tokugawa\":\n",
    "            rows[index][35] = 3\n",
    "        elif rows[index][35] == \"Odyssey\":\n",
    "            rows[index][35] = 4\n",
    "        \n",
    "        if index>0:\n",
    "            features_train.append([row for row in rows[index][1:28]])\n",
    "            labels_train.append(rows[index][35])\n",
    "        index += 1\n",
    "    import numpy as np\n",
    "    features_train = np.array(features_train).astype(np.float)\n",
    "    print features_train[0]\n",
    "    print labels_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60129\n"
     ]
    }
   ],
   "source": [
    "count_prev_impact = 0\n",
    "for i in range(len(features_train)):\n",
    "    if labels_train[i] == features_train[i][0]:\n",
    "        count_prev_impact += 1\n",
    "accuracy = count_prev_impact*1.0/len(features_train)\n",
    "print len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  6.  7.  0.  0.  0.  3.  2.  0.  0.  0.  0.  1.  0.  0.  0.  2.\n",
      "  2.  0.  0.  0.  8.  9.  0.  0.  3.]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Leaderboard_Dataset.csv', 'rb') as leader_csvfile:\n",
    "    spamreader = csv.reader(leader_csvfile, delimiter=' ', quotechar='|')\n",
    "    rows = []\n",
    "    features_test = []\n",
    "    index = 0\n",
    "    for row in spamreader:\n",
    "        rows.append(row[0].split(','))\n",
    "        \n",
    "        #change 1st column to corresponding value in int\n",
    "        if rows[index][1] == \"Centaur\":\n",
    "            rows[index][1] = 0\n",
    "        elif rows[index][1] == \"Ebony\":\n",
    "            rows[index][1] = 1\n",
    "        elif rows[index][1] == \"Cosmos\":\n",
    "            rows[index][1] = 2\n",
    "        elif rows[index][1] == \"Tokugawa\":\n",
    "            rows[index][1] = 3\n",
    "        elif rows[index][1] == \"Odyssey\":\n",
    "            rows[index][1] = 4\n",
    "            \n",
    "        if index>0:\n",
    "            features_test.append([row for row in rows[index][1:28]])\n",
    "        index += 1\n",
    "    features_test = np.array(features_test).astype(np.float)\n",
    "    print features_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Kings_In_The_North_IITRoorkee_3.csv', 'w') as train_output_csvfile:\n",
    "    writer = csv.writer(train_output_csvfile, delimiter=',', quotechar='|')\n",
    "    predstr = []\n",
    "    for i in range(len(features_test)):\n",
    "        if pred[i] == 0:\n",
    "            predstr.append(\"CENTAUR\")\n",
    "        elif pred[i] == 1:\n",
    "            predstr.append(\"EBONY\")\n",
    "        elif pred[i] == 2:\n",
    "            predstr.append(\"COSMOS\")\n",
    "        elif pred[i] == 3:\n",
    "            predstr.append(\"TOKUGAWA\")\n",
    "        elif pred[i] == 4:\n",
    "            predstr.append(\"ODYSSEY\")\n",
    "        writer.writerow((rows[i + 1][0], predstr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
