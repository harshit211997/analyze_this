{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0c8429cf6e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mfeatures_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlabels_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mfeatures_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Training_Dataset.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    rows = []\n",
    "    features_train = []\n",
    "    labels_train = []\n",
    "    index = 0\n",
    "    for row in spamreader:\n",
    "        rows.append(row[0].split(','))\n",
    "        \n",
    "        #change 1st column to corresponding value in int\n",
    "        if rows[index][1] == \"Centaur\":\n",
    "            rows[index][1] = 0\n",
    "        elif rows[index][1] == \"Ebony\":\n",
    "            rows[index][1] = 1\n",
    "        elif rows[index][1] == \"Cosmos\":\n",
    "            rows[index][1] = 2\n",
    "        elif rows[index][1] == \"Tokugawa\":\n",
    "            rows[index][1] = 3\n",
    "        elif rows[index][1] == \"Odyssey\":\n",
    "            rows[index][1] = 4\n",
    "            \n",
    "        if rows[index][35] == \"Centaur\":\n",
    "            rows[index][35] = 0\n",
    "        elif rows[index][35] == \"Ebony\":\n",
    "            rows[index][35] = 1\n",
    "        elif rows[index][35] == \"Cosmos\":\n",
    "            rows[index][35] = 2\n",
    "        elif rows[index][35] == \"Tokugawa\":\n",
    "            rows[index][35] = 3\n",
    "        elif rows[index][35] == \"Odyssey\":\n",
    "            rows[index][35] = 4\n",
    "        \n",
    "        if index>0:\n",
    "            features_train.append([row for row in rows[index][1:27]])\n",
    "            labels_train.append(rows[index][35]*1.0)\n",
    "            features_train[index].append(rows[index][32])\n",
    "                \n",
    "        index += 1\n",
    "    import numpy as np\n",
    "    features_train = np.array(features_train).astype(np.float)\n",
    "    print rows[0]\n",
    "    print rows[1]\n",
    "    print features_train[2]\n",
    "    print labels_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.5436663   0.61468745  0.69073877  0.68549242  0.58649203\n",
      "  0.4336443   0.42696078  0.48955242  0.57646832  0.45719185  0.16696861\n",
      "  0.12114366  0.2819466   0.20143001  0.26005467  0.08341025  0.31868618\n",
      "  0.34380495  0.14654529  0.01878419  0.26978359  0.2702677   0.55965399\n",
      "  0.50018906  0.31002716]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(features_train, labels_train)\n",
    "scores = (selector.scores_)\n",
    "scores /= scores.max()\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  6.  7.  0.  0.  0.  3.  2.  0.  0.  0.  0.  1.  0.  0.  0.  2.\n",
      "  2.  0.  0.  0.  8.  9.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Leaderboard_Dataset.csv', 'rb') as leader_csvfile:\n",
    "    spamreader = csv.reader(leader_csvfile, delimiter=' ', quotechar='|')\n",
    "    rows = []\n",
    "    features_test = []\n",
    "    index = 0\n",
    "    for row in spamreader:\n",
    "        rows.append(row[0].split(','))\n",
    "        \n",
    "        #change 1st column to corresponding value in int\n",
    "        if rows[index][1] == \"Centaur\":\n",
    "            rows[index][1] = 0\n",
    "        elif rows[index][1] == \"Ebony\":\n",
    "            rows[index][1] = 1\n",
    "        elif rows[index][1] == \"Cosmos\":\n",
    "            rows[index][1] = 2\n",
    "        elif rows[index][1] == \"Tokugawa\":\n",
    "            rows[index][1] = 3\n",
    "        elif rows[index][1] == \"Odyssey\":\n",
    "            rows[index][1] = 4\n",
    "            \n",
    "        if index>0:\n",
    "            features_test.append([row for row in rows[index][1:27]])\n",
    "        index += 1\n",
    "    features_test = np.array(features_test).astype(np.float)\n",
    "    print features_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class RandomizedPCA is deprecated; RandomizedPCA was deprecated in 0.18 and will be removed in 0.20. Use PCA(svd_solver='randomized') instead. The new implementation DOES NOT store whiten ``components_``. Apply transform to get them.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Kings_In_The_North_IITRoorkee_11.csv', 'wb') as train_output_csvfile:\n",
    "    writer = csv.writer(train_output_csvfile, delimiter=',', quotechar='|')\n",
    "    predstr = []\n",
    "    for i in range(len(features_test)):\n",
    "        if pred[i] == 0:\n",
    "            predstr.append(\"Centaur\")\n",
    "        elif pred[i] == 1:\n",
    "            predstr.append(\"Ebony\")\n",
    "        elif pred[i] == 2:\n",
    "            predstr.append(\"Cosmos\")\n",
    "        elif pred[i] == 3:\n",
    "            predstr.append(\"Tokugawa\")\n",
    "        elif pred[i] == 4:\n",
    "            predstr.append(\"Odyssey\")\n",
    "        writer.writerow((rows[i + 1][0], predstr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944768747194\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(features_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(pred, labels_train)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
